{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "obvious-handy",
   "metadata": {
    "papermill": {
     "duration": 0.032486,
     "end_time": "2021-04-26T05:19:33.495705",
     "exception": false,
     "start_time": "2021-04-26T05:19:33.463219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div align=\"center\">CM5</div>\n",
    "\n",
    "## 5.1 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eleven-dependence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:33.567853Z",
     "iopub.status.busy": "2021-04-26T05:19:33.567312Z",
     "iopub.status.idle": "2021-04-26T05:19:39.373036Z",
     "shell.execute_reply": "2021-04-26T05:19:39.373637Z"
    },
    "papermill": {
     "duration": 5.848181,
     "end_time": "2021-04-26T05:19:39.373991",
     "exception": false,
     "start_time": "2021-04-26T05:19:33.525810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fashionmnist/fashion_mnist_dataset_train.npy\n"
     ]
    }
   ],
   "source": [
    "# Handle table-like data and matrices :\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "        \n",
    "# Modelling Helpers Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "# Resnet \n",
    "import keras\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Machine Learning Model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time library\n",
    "import time \n",
    "\n",
    "\n",
    "# Classification\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-consequence",
   "metadata": {
    "papermill": {
     "duration": 0.046705,
     "end_time": "2021-04-26T05:19:39.465989",
     "exception": false,
     "start_time": "2021-04-26T05:19:39.419284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.2 Dataset Extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facial-carrier",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:39.669483Z",
     "iopub.status.busy": "2021-04-26T05:19:39.668947Z",
     "iopub.status.idle": "2021-04-26T05:19:44.896584Z",
     "shell.execute_reply": "2021-04-26T05:19:44.895693Z"
    },
    "papermill": {
     "duration": 5.278841,
     "end_time": "2021-04-26T05:19:44.896714",
     "exception": false,
     "start_time": "2021-04-26T05:19:39.617873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4    pixel5  pixel6  pixel7    pixel8  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0  0.000000   \n",
       "1     0.0     0.0     0.0     0.0     0.0  0.003922     0.0     0.0  0.000000   \n",
       "2     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0  0.000000   \n",
       "3     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0  0.129412   \n",
       "4     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0  0.000000   \n",
       "\n",
       "     pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0  0.000000  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "1  0.000000  ...  0.447059  0.509804  0.298039       0.0       0.0       0.0   \n",
       "2  0.086275  ...  0.000000  0.003922  0.000000       0.0       0.0       0.0   \n",
       "3  0.376471  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "4  0.000000  ...  0.000000  0.000000  0.000000       0.0       0.0       0.0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  target  \n",
       "0       0.0       0.0       0.0     4.0  \n",
       "1       0.0       0.0       0.0     1.0  \n",
       "2       0.0       0.0       0.0     0.0  \n",
       "3       0.0       0.0       0.0     1.0  \n",
       "4       0.0       0.0       0.0     0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('../input/fashionmnist/fashion_mnist_dataset_train.npy', allow_pickle=True).item()\n",
    "data = np.array(data)\n",
    "my_dict = data[()]\n",
    "features = my_dict.get('features')\n",
    "target = my_dict.get('target')\n",
    "farray = features.reshape(features.shape[0], (features.shape[1]*features.shape[2]))\n",
    "column_names = []\n",
    "[column_names.append(\"pixel\"+str(x)) for x in range(0, 784)]\n",
    "f1 = pd.DataFrame(farray , columns = column_names)\n",
    "column_names = ['target']\n",
    "t1  = pd.DataFrame(target , columns = column_names)\n",
    "f1['target'] = t1['target'] - 1\n",
    "f1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-syndicate",
   "metadata": {
    "papermill": {
     "duration": 0.03175,
     "end_time": "2021-04-26T05:19:44.960188",
     "exception": false,
     "start_time": "2021-04-26T05:19:44.928438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.3 Dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hidden-parcel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:45.026304Z",
     "iopub.status.busy": "2021-04-26T05:19:45.025731Z",
     "iopub.status.idle": "2021-04-26T05:19:45.029735Z",
     "shell.execute_reply": "2021-04-26T05:19:45.029328Z"
    },
    "papermill": {
     "duration": 0.038718,
     "end_time": "2021-04-26T05:19:45.029889",
     "exception": false,
     "start_time": "2021-04-26T05:19:44.991171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clothing2 = {0 : '1',\n",
    "            1 : '2',\n",
    "            2 : '3',\n",
    "            3 : '4',\n",
    "            4 : '5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cooked-worse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:45.110884Z",
     "iopub.status.busy": "2021-04-26T05:19:45.110105Z",
     "iopub.status.idle": "2021-04-26T05:19:48.169149Z",
     "shell.execute_reply": "2021-04-26T05:19:48.168709Z"
    },
    "papermill": {
     "duration": 3.108709,
     "end_time": "2021-04-26T05:19:48.169271",
     "exception": false,
     "start_time": "2021-04-26T05:19:45.060562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize = (15,15))\n",
    "for row in axes:\n",
    "    for axe in row:\n",
    "        index = np.random.randint(60000)\n",
    "        img = f1.drop('target', axis=1).values[index].reshape(28,28)\n",
    "        cloths = f1['target'][index]\n",
    "        axe.imshow(img, cmap='gray')\n",
    "        axe.set_title(clothing2[cloths])\n",
    "        axe.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-frank",
   "metadata": {
    "papermill": {
     "duration": 0.032035,
     "end_time": "2021-04-26T05:19:48.234310",
     "exception": false,
     "start_time": "2021-04-26T05:19:48.202275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-senate",
   "metadata": {
    "papermill": {
     "duration": 0.032694,
     "end_time": "2021-04-26T05:19:48.299380",
     "exception": false,
     "start_time": "2021-04-26T05:19:48.266686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.3.1 Setting Random Seeds for Reproducibilty :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "promising-institution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:48.369750Z",
     "iopub.status.busy": "2021-04-26T05:19:48.368568Z",
     "iopub.status.idle": "2021-04-26T05:19:48.371466Z",
     "shell.execute_reply": "2021-04-26T05:19:48.371061Z"
    },
    "papermill": {
     "duration": 0.039222,
     "end_time": "2021-04-26T05:19:48.371571",
     "exception": false,
     "start_time": "2021-04-26T05:19:48.332349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 66\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-flower",
   "metadata": {
    "papermill": {
     "duration": 0.0323,
     "end_time": "2021-04-26T05:19:48.436502",
     "exception": false,
     "start_time": "2021-04-26T05:19:48.404202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.3.2 Splitting Data into Train and Validation Set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "medium-distribution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:48.510185Z",
     "iopub.status.busy": "2021-04-26T05:19:48.509416Z",
     "iopub.status.idle": "2021-04-26T05:19:48.877930Z",
     "shell.execute_reply": "2021-04-26T05:19:48.877447Z"
    },
    "papermill": {
     "duration": 0.409164,
     "end_time": "2021-04-26T05:19:48.878059",
     "exception": false,
     "start_time": "2021-04-26T05:19:48.468895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = f1.iloc[:, :-1]\n",
    "Y = f1.iloc[:,784]\n",
    "x_train1, x_valtest, y_train, y_valtest = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "x_val1,x_test1,y_val,y_test = train_test_split(x_valtest, y_valtest, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-bunny",
   "metadata": {
    "papermill": {
     "duration": 0.03241,
     "end_time": "2021-04-26T05:19:48.943523",
     "exception": false,
     "start_time": "2021-04-26T05:19:48.911113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.3.3 Reshaping Image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complicated-paste",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:49.015342Z",
     "iopub.status.busy": "2021-04-26T05:19:49.014572Z",
     "iopub.status.idle": "2021-04-26T05:19:49.017374Z",
     "shell.execute_reply": "2021-04-26T05:19:49.016963Z"
    },
    "papermill": {
     "duration": 0.040473,
     "end_time": "2021-04-26T05:19:49.017484",
     "exception": false,
     "start_time": "2021-04-26T05:19:48.977011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = x_train1.values.reshape((-1, 28, 28, 1))\n",
    "x_val = x_val1.values.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test1.values.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-foundation",
   "metadata": {
    "papermill": {
     "duration": 0.032641,
     "end_time": "2021-04-26T05:19:49.082798",
     "exception": false,
     "start_time": "2021-04-26T05:19:49.050157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.3.4 One Hot Encoding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superb-local",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:49.153870Z",
     "iopub.status.busy": "2021-04-26T05:19:49.152720Z",
     "iopub.status.idle": "2021-04-26T05:19:49.161279Z",
     "shell.execute_reply": "2021-04-26T05:19:49.161995Z"
    },
    "papermill": {
     "duration": 0.046633,
     "end_time": "2021-04-26T05:19:49.162194",
     "exception": false,
     "start_time": "2021-04-26T05:19:49.115561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=5)\n",
    "y_val = to_categorical(y_val, num_classes=5)\n",
    "y_test = to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-theology",
   "metadata": {
    "papermill": {
     "duration": 0.05469,
     "end_time": "2021-04-26T05:19:49.273568",
     "exception": false,
     "start_time": "2021-04-26T05:19:49.218878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.4 Convolutional Neural Network :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-playing",
   "metadata": {
    "papermill": {
     "duration": 0.051586,
     "end_time": "2021-04-26T05:19:49.376155",
     "exception": false,
     "start_time": "2021-04-26T05:19:49.324569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.4.1 The design of Convolution neural networks definition :\n",
    "\n",
    "1) Firstly we used **Sequential Keras API** which is just a linear stack of layers.\n",
    "\n",
    "2) Then we include **Convolutional Layers**, this operation performs below operations :\n",
    "\n",
    "    1. Apply filters to extract features.\n",
    "\n",
    "    2. Apply activation function( in our case 'relu' ) on every every input value of feature maps.\n",
    "\n",
    "    3. Filters are composed of small kernels learned.\n",
    "\n",
    "3) Next we apply **Batch Normalization** to achieve zero mean and zero variance on image pixels after each convolution.\n",
    "\n",
    "4) Then we add **Max Pooling Layers**, which are used for Dimensionality Reduction or DownSampling the Input. These are used where we have lot of Input Features. It reduces the amount of Parameters and Computational power required drastically, thus reducing Overfitting. These along with Convolutional layers are able to learn more Complex features of the Image.\n",
    "\n",
    "5) We add **Dropout Layers** to avoid Overfitting. DropOut is a Regularization Technique, which Penalizes the Parameters. We DropOutRate to 0.25. Usually in general we can set this rate between 0.2-0.5.\n",
    "\n",
    "6) Then we include **Flatten layer** to map the input to a 1D vector. We then add Fully connected Layers after some convolutional/pooling layers.\n",
    "\n",
    "7) Lastly, we add the **Dense (Output) Layer**. It has units equal to the number of classes to be identified.Here, we use 'softmax' function since it is Multi-Class Classification. For binary classification we can use 'sigmoid' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fleet-peter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:49.488546Z",
     "iopub.status.busy": "2021-04-26T05:19:49.487736Z",
     "iopub.status.idle": "2021-04-26T05:19:52.525384Z",
     "shell.execute_reply": "2021-04-26T05:19:52.524450Z"
    },
    "papermill": {
     "duration": 3.096586,
     "end_time": "2021-04-26T05:19:52.525520",
     "exception": false,
     "start_time": "2021-04-26T05:19:49.428934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
    "                 data_format='channels_last', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
    "                 data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
    "                 data_format='channels_last'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', \n",
    "                 data_format='channels_last'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-senate",
   "metadata": {
    "papermill": {
     "duration": 0.032832,
     "end_time": "2021-04-26T05:19:52.591635",
     "exception": false,
     "start_time": "2021-04-26T05:19:52.558803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.4.2 Optimizer of the model :\n",
    "\n",
    "- Before model compilation we need to set optimizer used by the model. We have multiple options for optimizer e.g ADAM, SGD, ADAGRAD, ADADELTA, RMSPROP.\n",
    "\n",
    "**Parameters for Adam optimizer:**\n",
    "\n",
    "- learning rate : the learning rate is a configurable hyperparameter used in the training of neural networks. The learning rate controls how quickly the model is adapted to the problem.\n",
    "\n",
    "- beta1 : The exponential decay rate for the first moment estimates (e.g. 0.9).\n",
    "\n",
    "- beta2 : The exponential decay rate for the second-moment estimates (e.g. 0.999).\n",
    "\n",
    "![](http://www.linkpicture.com/q/1_osB82GKHBOT8k1idLqiqA-99.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-longitude",
   "metadata": {
    "papermill": {
     "duration": 0.033106,
     "end_time": "2021-04-26T05:19:52.658005",
     "exception": false,
     "start_time": "2021-04-26T05:19:52.624899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Learning rate adjustment :**\n",
    "\n",
    "- The learning rate controls how quickly the model is adapted to the problem.\n",
    "- Smaller learning rates require more training epochs given the smaller changes made to the weights each update.\n",
    "- Larger learning rates result in rapid changes and require fewer training epochs.\n",
    "\n",
    "**Problem with too large or small learning rate value :**\n",
    "\n",
    "- A learning rate that is too large can cause the model to converge too quickly to a suboptimal solution.\n",
    "- A learning rate that is too small can cause the process to get stuck.\n",
    "\n",
    "**Note :**\n",
    "\n",
    "The learning rate is perhaps the most important hyperparameter for each optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "average-match",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:52.733893Z",
     "iopub.status.busy": "2021-04-26T05:19:52.732087Z",
     "iopub.status.idle": "2021-04-26T05:19:52.734446Z",
     "shell.execute_reply": "2021-04-26T05:19:52.734873Z"
    },
    "papermill": {
     "duration": 0.043388,
     "end_time": "2021-04-26T05:19:52.735005",
     "exception": false,
     "start_time": "2021-04-26T05:19:52.691617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# SGD \n",
    "optimizer_sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# RMSProp\n",
    "from keras.optimizers import RMSprop\n",
    "optimizer_rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# Adagrad\n",
    "from keras.optimizers import Adagrad\n",
    "optimizer_adagrad = tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "\n",
    "# Adadelta\n",
    "from keras.optimizers import Adagrad\n",
    "optimizer_adadelta = tf.keras.optimizers.Adadelta(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-massachusetts",
   "metadata": {
    "papermill": {
     "duration": 0.032943,
     "end_time": "2021-04-26T05:19:52.801169",
     "exception": false,
     "start_time": "2021-04-26T05:19:52.768226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.4.3 Model compilation :\n",
    "\n",
    "- During model compile we need to specify the loss function for the neural network which we want to minimize. For Multi-class Classification we use \"categorical_crossentropy\" and for Binary Classification we use \"binary_crossentropy\".\n",
    "\n",
    "- We need to specify the metric to evaluate our models performance. Here we used accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beautiful-welding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:52.873176Z",
     "iopub.status.busy": "2021-04-26T05:19:52.872434Z",
     "iopub.status.idle": "2021-04-26T05:19:52.884396Z",
     "shell.execute_reply": "2021-04-26T05:19:52.883954Z"
    },
    "papermill": {
     "duration": 0.050398,
     "end_time": "2021-04-26T05:19:52.884504",
     "exception": false,
     "start_time": "2021-04-26T05:19:52.834106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-switzerland",
   "metadata": {
    "papermill": {
     "duration": 0.032739,
     "end_time": "2021-04-26T05:19:52.950252",
     "exception": false,
     "start_time": "2021-04-26T05:19:52.917513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.4.4 Model Summary :\n",
    "\n",
    "Summary shows below things of our model :\n",
    "\n",
    "* The layers and their order in the model.\n",
    "* The output shape of each layer.\n",
    "* The number of parameters (weights) in each layer.\n",
    "* The total number of parameters (weights) in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "parallel-scholarship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:53.025482Z",
     "iopub.status.busy": "2021-04-26T05:19:53.024624Z",
     "iopub.status.idle": "2021-04-26T05:19:53.036798Z",
     "shell.execute_reply": "2021-04-26T05:19:53.036400Z"
    },
    "papermill": {
     "duration": 0.053239,
     "end_time": "2021-04-26T05:19:53.036935",
     "exception": false,
     "start_time": "2021-04-26T05:19:52.983696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 13,017,125\n",
      "Trainable params: 13,015,461\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-generator",
   "metadata": {
    "papermill": {
     "duration": 0.033437,
     "end_time": "2021-04-26T05:19:53.104297",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.070860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.4.5 Learning Rate Decay :\n",
    "\n",
    "- We should tuned our learning so that it is not too high to take very large steps, neither it should be too small which not change weights and bias of the model.\n",
    "- We use LearningRateScheduler here, which takes the step decay function as argument and return the updated learning rates for use in optimzer at every epoch stage.\n",
    "- So at every epoch learning rate will be change by LearningRateScheduler.\n",
    "- LearningRateScheduler callback that allows you to specify a function that is called each epoch in order to adjust the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "massive-speech",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:53.177826Z",
     "iopub.status.busy": "2021-04-26T05:19:53.176360Z",
     "iopub.status.idle": "2021-04-26T05:19:53.178829Z",
     "shell.execute_reply": "2021-04-26T05:19:53.179236Z"
    },
    "papermill": {
     "duration": 0.041488,
     "end_time": "2021-04-26T05:19:53.179366",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.137878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-abuse",
   "metadata": {
    "papermill": {
     "duration": 0.033321,
     "end_time": "2021-04-26T05:19:53.246618",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.213297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- As an alternate solution of LearningRateScheduler we can also use **ReduceLROnPlateau**.\n",
    "- The ReduceLROnPlateau that will adjust the learning rate when a plateau in model performance is detected.\n",
    "- This callback is designed to reduce the learning rate after the model stops improving with the hope of fine-tuning model weights.\n",
    "- ReduceLROnPlateau works like EarlyStopping, with three parameters: monitor, patience and mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-intervention",
   "metadata": {
    "papermill": {
     "duration": 0.033509,
     "end_time": "2021-04-26T05:19:53.313492",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.279983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Parameters of ReduceLROnPlateau :**\n",
    "\n",
    "1) min_lr : The lowest value for the learning rate in model.\n",
    "\n",
    "2) patience : number of epochs with no improvement after which learning rate will be reduced.\n",
    "\n",
    "3) monitor: quantity to be monitored. (i.e val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "structured-sixth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:53.385482Z",
     "iopub.status.busy": "2021-04-26T05:19:53.384956Z",
     "iopub.status.idle": "2021-04-26T05:19:53.388649Z",
     "shell.execute_reply": "2021-04-26T05:19:53.388143Z"
    },
    "papermill": {
     "duration": 0.041239,
     "end_time": "2021-04-26T05:19:53.388752",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.347513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr= ReduceLROnPlateau(monitor='val_accuracy', factor=.01,  patience=3, min_lr=1e-5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-today",
   "metadata": {
    "papermill": {
     "duration": 0.033489,
     "end_time": "2021-04-26T05:19:53.456106",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.422617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.4.6 Data Augmentation :\n",
    "\n",
    "- Data Augmentation is like adding a data and/or noise to a dataset, so that model can perform well in various patterns.\n",
    "- For example, what if our images will have object at some angle ? In that case mostly our model will fail to predict right label.\n",
    "- So using data augmentation our model will build with different variations so that model performance on variety of input will remain same.\n",
    "- Image data augmentation is supported in the Keras deep learning library via the ImageDataGenerator class.\n",
    "\n",
    "**Parameters we used in  ImageDataGenerator :**\n",
    "\n",
    "1) **rotation_range :** (Integer) Degree range for random rotations.\n",
    "\n",
    "2) **zoom_range :** (Float or [lower, upper]) Range for random zoom.\n",
    "\n",
    "3) **shear_range :** (Float) Shear Intensity (Shear angle in counter-clockwise direction in degrees).\n",
    "\n",
    "4) **width_shift_range :** (Float, 1-D array-like or int - float) fraction of total width, if < 1, or pixels if >= 1. - 1-D array-like: random elements from the array. - int: integer number of pixels from interval.\n",
    "\n",
    "5) **height_shift_range :** (Float, 1-D array-like or int - float) fraction of total height, if < 1, or pixels if >= 1. - 1-D array-like: random elements from the array. - int: integer number of pixels from interval.\n",
    "\n",
    "6) **vertical_flip :** (Boolean) Randomly flip inputs vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "organizational-albert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:53.529693Z",
     "iopub.status.busy": "2021-04-26T05:19:53.527975Z",
     "iopub.status.idle": "2021-04-26T05:19:53.530334Z",
     "shell.execute_reply": "2021-04-26T05:19:53.530757Z"
    },
    "papermill": {
     "duration": 0.041126,
     "end_time": "2021-04-26T05:19:53.530895",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.489769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        shear_range = 0.3,# shear angle in counter-clockwise direction in degrees  \n",
    "        width_shift_range=0.08,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
    "        vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amateur-bahrain",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:53.603308Z",
     "iopub.status.busy": "2021-04-26T05:19:53.602268Z",
     "iopub.status.idle": "2021-04-26T05:19:53.715583Z",
     "shell.execute_reply": "2021-04-26T05:19:53.715125Z"
    },
    "papermill": {
     "duration": 0.150631,
     "end_time": "2021-04-26T05:19:53.715711",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.565080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-farming",
   "metadata": {
    "papermill": {
     "duration": 0.034275,
     "end_time": "2021-04-26T05:19:53.784763",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.750488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.4.7 Model fitting :\n",
    "\n",
    "- **batch size :** The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters.\n",
    "- **epochs :** The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deadly-rhythm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:53.857875Z",
     "iopub.status.busy": "2021-04-26T05:19:53.857072Z",
     "iopub.status.idle": "2021-04-26T05:19:53.859386Z",
     "shell.execute_reply": "2021-04-26T05:19:53.859899Z"
    },
    "papermill": {
     "duration": 0.041245,
     "end_time": "2021-04-26T05:19:53.860029",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.818784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indonesian-guyana",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:19:53.934608Z",
     "iopub.status.busy": "2021-04-26T05:19:53.933612Z",
     "iopub.status.idle": "2021-04-26T05:26:34.592531Z",
     "shell.execute_reply": "2021-04-26T05:26:34.591935Z"
    },
    "papermill": {
     "duration": 400.698393,
     "end_time": "2021-04-26T05:26:34.592696",
     "exception": false,
     "start_time": "2021-04-26T05:19:53.894303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 - 20s - loss: 0.8106 - accuracy: 0.6799 - val_loss: 2.1567 - val_accuracy: 0.3357\n",
      "Epoch 2/25\n",
      "375/375 - 15s - loss: 0.5759 - accuracy: 0.7659 - val_loss: 0.5030 - val_accuracy: 0.7878\n",
      "Epoch 3/25\n",
      "375/375 - 15s - loss: 0.5204 - accuracy: 0.7875 - val_loss: 0.4177 - val_accuracy: 0.8318\n",
      "Epoch 4/25\n",
      "375/375 - 17s - loss: 0.4909 - accuracy: 0.8031 - val_loss: 0.5545 - val_accuracy: 0.7827\n",
      "Epoch 5/25\n",
      "375/375 - 16s - loss: 0.4641 - accuracy: 0.8135 - val_loss: 0.3826 - val_accuracy: 0.8477\n",
      "Epoch 6/25\n",
      "375/375 - 16s - loss: 0.4483 - accuracy: 0.8198 - val_loss: 0.4014 - val_accuracy: 0.8283\n",
      "Epoch 7/25\n",
      "375/375 - 15s - loss: 0.4383 - accuracy: 0.8236 - val_loss: 0.3356 - val_accuracy: 0.8635\n",
      "Epoch 8/25\n",
      "375/375 - 16s - loss: 0.4191 - accuracy: 0.8316 - val_loss: 0.4851 - val_accuracy: 0.8005\n",
      "Epoch 9/25\n",
      "375/375 - 15s - loss: 0.4138 - accuracy: 0.8355 - val_loss: 0.3199 - val_accuracy: 0.8703\n",
      "Epoch 10/25\n",
      "375/375 - 16s - loss: 0.3981 - accuracy: 0.8423 - val_loss: 0.3404 - val_accuracy: 0.8545\n",
      "Epoch 11/25\n",
      "375/375 - 15s - loss: 0.3982 - accuracy: 0.8407 - val_loss: 0.3041 - val_accuracy: 0.8720\n",
      "Epoch 12/25\n",
      "375/375 - 16s - loss: 0.3867 - accuracy: 0.8440 - val_loss: 0.3602 - val_accuracy: 0.8447\n",
      "Epoch 13/25\n",
      "375/375 - 16s - loss: 0.3781 - accuracy: 0.8508 - val_loss: 0.3642 - val_accuracy: 0.8445\n",
      "Epoch 14/25\n",
      "375/375 - 16s - loss: 0.3705 - accuracy: 0.8541 - val_loss: 0.3734 - val_accuracy: 0.8415\n",
      "Epoch 15/25\n",
      "375/375 - 16s - loss: 0.3718 - accuracy: 0.8503 - val_loss: 0.5279 - val_accuracy: 0.7862\n",
      "Epoch 16/25\n",
      "375/375 - 16s - loss: 0.3653 - accuracy: 0.8557 - val_loss: 0.3531 - val_accuracy: 0.8472\n",
      "Epoch 17/25\n",
      "375/375 - 16s - loss: 0.3582 - accuracy: 0.8581 - val_loss: 0.3650 - val_accuracy: 0.8433\n",
      "Epoch 18/25\n",
      "375/375 - 16s - loss: 0.3541 - accuracy: 0.8604 - val_loss: 0.2928 - val_accuracy: 0.8770\n",
      "Epoch 19/25\n",
      "375/375 - 16s - loss: 0.3511 - accuracy: 0.8603 - val_loss: 0.3113 - val_accuracy: 0.8698\n",
      "Epoch 20/25\n",
      "375/375 - 16s - loss: 0.3501 - accuracy: 0.8617 - val_loss: 0.3845 - val_accuracy: 0.8360\n",
      "Epoch 21/25\n",
      "375/375 - 15s - loss: 0.3431 - accuracy: 0.8654 - val_loss: 0.3851 - val_accuracy: 0.8360\n",
      "Epoch 22/25\n",
      "375/375 - 16s - loss: 0.3412 - accuracy: 0.8671 - val_loss: 0.4382 - val_accuracy: 0.8218\n",
      "Epoch 23/25\n",
      "375/375 - 17s - loss: 0.3426 - accuracy: 0.8632 - val_loss: 0.4460 - val_accuracy: 0.8177\n",
      "Epoch 24/25\n",
      "375/375 - 16s - loss: 0.3358 - accuracy: 0.8670 - val_loss: 0.3110 - val_accuracy: 0.8688\n",
      "Epoch 25/25\n",
      "375/375 - 16s - loss: 0.3341 - accuracy: 0.8681 - val_loss: 0.4659 - val_accuracy: 0.8095\n",
      "--- 400.65404772758484 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, \n",
    "                              validation_data = (x_val, y_val), verbose=2, \n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                              callbacks = [reduce_lr])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "technological-ethiopia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:26:34.697087Z",
     "iopub.status.busy": "2021-04-26T05:26:34.696142Z",
     "iopub.status.idle": "2021-04-26T05:26:35.301653Z",
     "shell.execute_reply": "2021-04-26T05:26:35.301014Z"
    },
    "papermill": {
     "duration": 0.659485,
     "end_time": "2021-04-26T05:26:35.301837",
     "exception": false,
     "start_time": "2021-04-26T05:26:34.642352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 3ms/step - loss: 0.4659 - accuracy: 0.8095\n",
      "Loss: 0.4659\n",
      "Accuracy: 0.8095\n",
      "--- 0.6016826629638672 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "score = model.evaluate(x_val, y_val)\n",
    "\n",
    "print('Loss: {:.4f}'.format(score[0]))\n",
    "print('Accuracy: {:.4f}'.format(score[1]))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-billion",
   "metadata": {
    "papermill": {
     "duration": 0.051568,
     "end_time": "2021-04-26T05:26:35.406689",
     "exception": false,
     "start_time": "2021-04-26T05:26:35.355121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5.4.7 Optimization and result with model :\n",
    "\n",
    "\n",
    "1. **AdamGrad ( Learning rate : 0.01 ) :**\n",
    "- Epoch 5/5\n",
    "375/375 - 246s - loss: 0.9002 - accuracy: 0.6537 - val_loss: 0.5834 - val_accuracy: 0.7535\n",
    "\n",
    "- Adaptive Gradient Algorithm (Adagrad) is an algorithm for gradient-based optimization. ... It performs smaller updates As a result, it is well-suited when dealing with sparse data (NLP or image recognition).\n",
    "\n",
    "\n",
    "2. **Adam ( Learning rate : 0.01 ) :**\n",
    "\n",
    "- Epoch 5/5\n",
    "375/375 - 256s - loss: 0.4789 - accuracy: 0.8052 - val_loss: 0.4912 - val_accuracy: 0.7988\n",
    "\n",
    "- Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.\n",
    "\n",
    "\n",
    "3. **SGD ( Learning rate : 0.01 ) :**\n",
    "- Epoch 5/5\n",
    "375/375 - 227s - loss: 1.0482 - accuracy: 0.6044 - val_loss: 0.6966 - val_accuracy: 0.7113\n",
    "\n",
    "- The SGD class that implements the stochastic gradient descent optimizer with a learning rate and momentum.\n",
    "\n",
    "4. **RMSProp ( Learning rate : 0.01 ) :**\n",
    "\n",
    "- Epoch 5/5\n",
    "375/375 - 271s - loss: 0.4527 - accuracy: 0.8188 - val_loss: 0.5517 - val_accuracy: 0.7843\n",
    "\n",
    "- RmsProp optimizer is an optimizer that utilizes the magnitude of recent gradients to normalize the gradients.\n",
    "\n",
    "\n",
    "\n",
    "5. **Adadelta ( Learning rate : 0.01 ) :**\n",
    "\n",
    "- Epoch 5/5\n",
    "375/375 - 255s - loss: 1.6791 - accuracy: 0.4668 - val_loss: 1.0540 - val_accuracy: 0.6050\n",
    "\n",
    "\n",
    "**Note :**\n",
    "- Result of every epoch are included in CM6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-hopkins",
   "metadata": {
    "papermill": {
     "duration": 0.050871,
     "end_time": "2021-04-26T05:26:35.509808",
     "exception": false,
     "start_time": "2021-04-26T05:26:35.458937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.5 Resnet ( Model 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-covering",
   "metadata": {
    "papermill": {
     "duration": 0.052033,
     "end_time": "2021-04-26T05:26:35.614159",
     "exception": false,
     "start_time": "2021-04-26T05:26:35.562126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- In Resnet model we have to create residuals mappings. Residual mapping is the difference between the input and output of the residual block under question.\n",
    "- In other words, residual mapping is the value that will be added to the input to approximate the final function of the block.\n",
    "- We can consider the residual mapping is the amount of error which can be added to input so as to reach the final destination i.e. to approximate the final function.\n",
    "\n",
    "![](https://cdn-5f733ed3c1ac190fbc56ef88.closte.com/wp-content/uploads/2019/07/visualize_identity_mapping.png)\n",
    "\n",
    "- From above figure the Residual Mapping is acting as a bridge between the input and the output of the block.\n",
    "\n",
    "**Note :**\n",
    "- The weight layers and activation function are not shown in the diagram but they are actually present in the network.\n",
    "\n",
    "- The function which should be learned as a final result of the block is represented as H(x). The input to the block is x and the residual mapping.\n",
    "\n",
    "\n",
    "A RESIDUAL FUNCTION i.e. **F(x) = H(x) â€“ x**.\n",
    "\n",
    "**Residual function in Resnet model :**\n",
    "\n",
    "1. During training the deep residual network, the main focus is to learn the residual function i.e. F(x). So, if the network will somehow learn the difference (F(x)) between the input and output, then the overall accuracy can be increased. \n",
    "\n",
    "2. In other words, the residual value should be learned in a way such that it approaches zero, therefore making the identity mapping optimal.\n",
    "\n",
    "3. In this way, all the layers in the network will always produce the optimal feature maps i.e. the best case feature map after the convolution, pooling and activation operations.\n",
    "\n",
    "\n",
    "**Other parameters we used in Resnet in Conv2D :**\n",
    "1. **kernel_initializer:** Initializer for the kernel weights matrix.\n",
    "2. **kernel_regularizer:** Regularizer function applied to the kernel weights matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "environmental-gathering",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:26:35.733615Z",
     "iopub.status.busy": "2021-04-26T05:26:35.732718Z",
     "iopub.status.idle": "2021-04-26T05:26:36.069087Z",
     "shell.execute_reply": "2021-04-26T05:26:36.068066Z"
    },
    "papermill": {
     "duration": 0.403701,
     "end_time": "2021-04-26T05:26:36.069221",
     "exception": false,
     "start_time": "2021-04-26T05:26:35.665520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = (28, 28,1)\n",
    "num_filters = 64\n",
    "use_max_pool = False\n",
    "num_blocks = 4\n",
    "num_sub_blocks = 2\n",
    "num_classes = 5\n",
    "inputs = Input(shape=input_size)\n",
    "con_x = Conv2D(num_filters, padding='same', \n",
    "           kernel_initializer='he_normal', \n",
    "           kernel_size=7, strides=2,\n",
    "           kernel_regularizer=l2(1e-4))(inputs)\n",
    "con_x = BatchNormalization()(con_x)\n",
    "con_x = Activation('relu')(con_x)\n",
    "\n",
    "#Check by applying max pooling later (setting it false as size of image is small i.e. 28x28)\n",
    "if use_max_pool:\n",
    "    con_x = MaxPooling2D(pool_size=3,padding='same', strides=2)(con_x)\n",
    "    num_blocks =3\n",
    "#Creating Conv base stack \n",
    "\n",
    "# Instantiate convolutional base (stack of blocks).\n",
    "for i in range(num_blocks):\n",
    "    for j in range(num_sub_blocks):\n",
    "        strides = 1\n",
    "        is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "        if is_first_layer_but_not_first_block:\n",
    "            strides = 2\n",
    "        #Creating residual mapping using y\n",
    "        con_y = Conv2D(num_filters,\n",
    "                   kernel_size=3,\n",
    "                   padding='same',\n",
    "                   strides=strides,\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(con_x)\n",
    "        con_y = BatchNormalization()(con_y)\n",
    "        con_y = Activation('relu')(con_y)\n",
    "        con_y = Conv2D(num_filters,\n",
    "                   kernel_size=3,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(con_y)\n",
    "        con_y = BatchNormalization()(con_y)\n",
    "        if is_first_layer_but_not_first_block:\n",
    "            con_x = Conv2D(num_filters,\n",
    "                       kernel_size=1,\n",
    "                       padding='same',\n",
    "                       strides=2,\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2(1e-4))(con_x)\n",
    "        #Adding back residual mapping\n",
    "        con_x = keras.layers.add([con_x, con_y])\n",
    "        con_x = Activation('relu')(con_x)\n",
    "\n",
    "    num_filters = 2 * num_filters\n",
    "\n",
    "# Add classifier on top.\n",
    "con_x = AveragePooling2D()(con_x)\n",
    "con_y = Flatten()(con_x)\n",
    "outputs = Dense(num_classes,\n",
    "                activation='softmax',\n",
    "                kernel_initializer='he_normal')(con_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pressed-license",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:26:36.186184Z",
     "iopub.status.busy": "2021-04-26T05:26:36.182150Z",
     "iopub.status.idle": "2021-04-26T05:26:36.215260Z",
     "shell.execute_reply": "2021-04-26T05:26:36.215641Z"
    },
    "papermill": {
     "duration": 0.092865,
     "end_time": "2021-04-26T05:26:36.215788",
     "exception": false,
     "start_time": "2021-04-26T05:26:36.122923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 64)   3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 14, 14, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 14, 14, 64)   36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 14, 14, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 14, 14, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 14, 14, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 14, 14, 64)   0           activation[0][0]                 \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 14, 14, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 14, 14, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 14, 14, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 64)   0           activation_2[0][0]               \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 14, 14, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 128)    73856       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 7, 7, 128)    512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7, 7, 128)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 128)    147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 128)    8320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 7, 7, 128)    512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 128)    0           conv2d_11[0][0]                  \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 7, 7, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 128)    147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 128)    512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           activation_6[0][0]               \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 256)    295168      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4, 4, 256)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 256)    590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 256)    33024       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 256)    0           conv2d_16[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 256)    590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 256)    1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 256)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 256)    590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 256)    0           activation_10[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 256)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 2, 2, 512)    1180160     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 2, 2, 512)    2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2, 2, 512)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 2, 2, 512)    2359808     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 2, 2, 512)    131584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 2, 2, 512)    2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2, 2, 512)    0           conv2d_21[0][0]                  \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2, 2, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 2, 2, 512)    2359808     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 2, 2, 512)    2048        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 2, 512)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 2, 2, 512)    2359808     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 2, 2, 512)    2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 512)    0           activation_14[0][0]              \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2, 2, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 512)    0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            2565        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,183,621\n",
      "Trainable params: 11,175,813\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and compile model.\n",
    "resmodel = Model(inputs=inputs, outputs=outputs)\n",
    "resmodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "resmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "attempted-campus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:26:36.338327Z",
     "iopub.status.busy": "2021-04-26T05:26:36.334907Z",
     "iopub.status.idle": "2021-04-26T05:26:36.341315Z",
     "shell.execute_reply": "2021-04-26T05:26:36.341702Z"
    },
    "papermill": {
     "duration": 0.062674,
     "end_time": "2021-04-26T05:26:36.341845",
     "exception": false,
     "start_time": "2021-04-26T05:26:36.279171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/saved_model/fmnist_resnet_model.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_model')\n",
    "model_name = 'fmnist_resnet_model.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir,model_name)\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-median",
   "metadata": {
    "papermill": {
     "duration": 0.052072,
     "end_time": "2021-04-26T05:26:36.445881",
     "exception": false,
     "start_time": "2021-04-26T05:26:36.393809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**ModelCheckpoint :**\n",
    "\n",
    "- ModelCheckpoint save the best version of your model after a single training.\n",
    "- During saving we can select save_best_only and save_weights_only: The first will save the complete model with better training performance; The other will save only the weight values for this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dental-amber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:26:36.557930Z",
     "iopub.status.busy": "2021-04-26T05:26:36.556097Z",
     "iopub.status.idle": "2021-04-26T05:26:36.558483Z",
     "shell.execute_reply": "2021-04-26T05:26:36.558882Z"
    },
    "papermill": {
     "duration": 0.060385,
     "end_time": "2021-04-26T05:26:36.559010",
     "exception": false,
     "start_time": "2021-04-26T05:26:36.498625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-pacific",
   "metadata": {
    "papermill": {
     "duration": 0.051903,
     "end_time": "2021-04-26T05:26:36.663287",
     "exception": false,
     "start_time": "2021-04-26T05:26:36.611384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Comparision of LearningRateScheduler and ReduceLROnPlateau are included in CM6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "varying-empty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:26:36.789961Z",
     "iopub.status.busy": "2021-04-26T05:26:36.789140Z",
     "iopub.status.idle": "2021-04-26T05:31:28.283701Z",
     "shell.execute_reply": "2021-04-26T05:31:28.284281Z"
    },
    "papermill": {
     "duration": 291.56875,
     "end_time": "2021-04-26T05:31:28.284497",
     "exception": false,
     "start_time": "2021-04-26T05:26:36.715747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - 15s 32ms/step - loss: 1.6841 - accuracy: 0.7555 - val_loss: 1.1087 - val_accuracy: 0.8332\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.10869, saving model to /kaggle/working/saved_model/fmnist_resnet_model.h5\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.9823 - accuracy: 0.8681 - val_loss: 0.8282 - val_accuracy: 0.8767\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.10869 to 0.82815, saving model to /kaggle/working/saved_model/fmnist_resnet_model.h5\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.7506 - accuracy: 0.8941 - val_loss: 0.7199 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.82815 to 0.71990, saving model to /kaggle/working/saved_model/fmnist_resnet_model.h5\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.6387 - accuracy: 0.8999 - val_loss: 0.6921 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.71990 to 0.69214, saving model to /kaggle/working/saved_model/fmnist_resnet_model.h5\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.5522 - accuracy: 0.9104 - val_loss: 0.6032 - val_accuracy: 0.8812\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.69214 to 0.60323, saving model to /kaggle/working/saved_model/fmnist_resnet_model.h5\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.5021 - accuracy: 0.9155 - val_loss: 0.9253 - val_accuracy: 0.7907\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.60323\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.4579 - accuracy: 0.9219 - val_loss: 0.5643 - val_accuracy: 0.8748\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60323 to 0.56433, saving model to /kaggle/working/saved_model/fmnist_resnet_model.h5\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.4205 - accuracy: 0.9291 - val_loss: 0.5172 - val_accuracy: 0.8932\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56433 to 0.51716, saving model to /kaggle/working/saved_model/fmnist_resnet_model.h5\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.4025 - accuracy: 0.9301 - val_loss: 0.6454 - val_accuracy: 0.8533\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.51716\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3829 - accuracy: 0.9334 - val_loss: 0.5331 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.51716\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3689 - accuracy: 0.9380 - val_loss: 0.6069 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.51716\n",
      "Epoch 12/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3559 - accuracy: 0.9398 - val_loss: 0.5403 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.51716\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3346 - accuracy: 0.9462 - val_loss: 0.5604 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.51716\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.2793 - accuracy: 0.9656 - val_loss: 0.5032 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.51716 to 0.50325, saving model to /kaggle/working/saved_model/fmnist_resnet_model.h5\n",
      "Epoch 15/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.2293 - accuracy: 0.9798 - val_loss: 0.5364 - val_accuracy: 0.9003\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.50325\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.2120 - accuracy: 0.9817 - val_loss: 0.5712 - val_accuracy: 0.8937\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.50325\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.2072 - accuracy: 0.9817 - val_loss: 0.5480 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.50325\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.1944 - accuracy: 0.9842 - val_loss: 0.5718 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.50325\n",
      "Epoch 19/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.1874 - accuracy: 0.9848 - val_loss: 0.6879 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.50325\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.1634 - accuracy: 0.9930 - val_loss: 0.5765 - val_accuracy: 0.9072\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.50325\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - 11s 31ms/step - loss: 0.1496 - accuracy: 0.9965 - val_loss: 0.5778 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.50325\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.1447 - accuracy: 0.9972 - val_loss: 0.6340 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.50325\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.1396 - accuracy: 0.9974 - val_loss: 0.6178 - val_accuracy: 0.9033\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.50325\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.1367 - accuracy: 0.9976 - val_loss: 0.6877 - val_accuracy: 0.8993\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.50325\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.1348 - accuracy: 0.9979 - val_loss: 0.6234 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.50325\n",
      "--- 291.4898257255554 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "resmodel.fit(x_train, y_train, batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_val, y_val),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "interior-symposium",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:31:30.868960Z",
     "iopub.status.busy": "2021-04-26T05:31:30.868028Z",
     "iopub.status.idle": "2021-04-26T05:31:32.300096Z",
     "shell.execute_reply": "2021-04-26T05:31:32.300683Z"
    },
    "papermill": {
     "duration": 2.728859,
     "end_time": "2021-04-26T05:31:32.300897",
     "exception": false,
     "start_time": "2021-04-26T05:31:29.572038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6234 - accuracy: 0.9110\n",
      "Loss: 0.6234\n",
      "Accuracy: 0.9110\n",
      "--- 1.429495096206665 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "score = resmodel.evaluate(x_val, y_val)\n",
    "\n",
    "print('Loss: {:.4f}'.format(score[0]))\n",
    "print('Accuracy: {:.4f}'.format(score[1]))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-grant",
   "metadata": {
    "papermill": {
     "duration": 1.557559,
     "end_time": "2021-04-26T05:31:35.184848",
     "exception": false,
     "start_time": "2021-04-26T05:31:33.627289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Advantages of Resnet :**\n",
    "- ResNet uses Batch Normalization at its core. The Batch Normalization adjusts the input layer to increase the performance of the network.\n",
    "- ResNet makes use of the Identity Connection, which helps to protect the network from vanishing gradient problem.\n",
    "- Deep Residual Network uses bottleneck residual block design to increase the performance of the network.\n",
    "\n",
    "**Limitations of Resnet :**\n",
    "- Increased complexity of architecture.\n",
    "- Deeper network usually requires weeks for training, making it practically infeasible in real-world applications.\n",
    "- Implementation of Batch normalization layers since ResNet heavily depends on it.\n",
    "- The dimensionality between the different layers which can become a headache while adding skip connections in model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-findings",
   "metadata": {
    "papermill": {
     "duration": 1.30157,
     "end_time": "2021-04-26T05:31:37.788847",
     "exception": false,
     "start_time": "2021-04-26T05:31:36.487277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.6 ML model ( Random Forest with Gridsearch ) :\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "- **n_estimators :** number of trees in the forest.\n",
    "- **max_depth :** max number of levels in each decision tree.\n",
    "- **bootstrap :** method for sampling data points (with or without replacement).\n",
    "\n",
    "Other parameters can use :\n",
    "\n",
    "- **max_features :** max number of features considered for splitting a node.\n",
    "- **min_samples_split :** min number of data points placed in a node before the node is split.\n",
    "- **min_samples_leaf :** min number of data points allowed in a leaf node.\n",
    "\n",
    "**GridSearchCV :**\n",
    "\n",
    "- GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter.\n",
    "\n",
    "\n",
    "**Note :**\n",
    "\n",
    "- Instead of GridSearchCV we can also use RandomizedSearchCV, which implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "attempted-semiconductor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:31:40.410558Z",
     "iopub.status.busy": "2021-04-26T05:31:40.409616Z",
     "iopub.status.idle": "2021-04-26T05:31:40.411348Z",
     "shell.execute_reply": "2021-04-26T05:31:40.412128Z"
    },
    "papermill": {
     "duration": 1.299357,
     "end_time": "2021-04-26T05:31:40.412278",
     "exception": false,
     "start_time": "2021-04-26T05:31:39.112921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [3,5,10, None],\n",
    "    'n_estimators': [5,10,50, 150, 200]\n",
    "}\n",
    "# Create a based model\n",
    "rfc = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rfc, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "promotional-junction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:31:43.003260Z",
     "iopub.status.busy": "2021-04-26T05:31:43.002394Z",
     "iopub.status.idle": "2021-04-26T05:50:44.614803Z",
     "shell.execute_reply": "2021-04-26T05:50:44.615336Z"
    },
    "papermill": {
     "duration": 1142.910024,
     "end_time": "2021-04-26T05:50:44.615494",
     "exception": false,
     "start_time": "2021-04-26T05:31:41.705470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True, 'max_depth': None, 'n_estimators': 200}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train1,y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "subtle-kazakhstan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:50:47.187760Z",
     "iopub.status.busy": "2021-04-26T05:50:47.186686Z",
     "iopub.status.idle": "2021-04-26T05:50:47.825176Z",
     "shell.execute_reply": "2021-04-26T05:50:47.824618Z"
    },
    "papermill": {
     "duration": 1.94203,
     "end_time": "2021-04-26T05:50:47.825321",
     "exception": false,
     "start_time": "2021-04-26T05:50:45.883291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_rf = grid_search.predict(x_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "joined-seminar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:50:50.703971Z",
     "iopub.status.busy": "2021-04-26T05:50:50.703219Z",
     "iopub.status.idle": "2021-04-26T05:50:50.712467Z",
     "shell.execute_reply": "2021-04-26T05:50:50.711801Z"
    },
    "papermill": {
     "duration": 1.301518,
     "end_time": "2021-04-26T05:50:50.712617",
     "exception": false,
     "start_time": "2021-04-26T05:50:49.411099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8116666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy :',metrics.accuracy_score(y_val,y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-biography",
   "metadata": {
    "papermill": {
     "duration": 1.262632,
     "end_time": "2021-04-26T05:50:53.278744",
     "exception": false,
     "start_time": "2021-04-26T05:50:52.016112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.7 Simple Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-disposition",
   "metadata": {
    "papermill": {
     "duration": 1.271601,
     "end_time": "2021-04-26T05:50:55.840239",
     "exception": false,
     "start_time": "2021-04-26T05:50:54.568638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- In this model we havn't use any convolution or max polling layer in model. We simply use Flatter and Dense in model and trained it with learning rate.\n",
    "\n",
    "- We try to create a model on paper below is an overview on a model :\n",
    "\n",
    "![](http://www.linkpicture.com/q/0001_33.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "neutral-spine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:50:58.464759Z",
     "iopub.status.busy": "2021-04-26T05:50:58.463774Z",
     "iopub.status.idle": "2021-04-26T05:50:58.489717Z",
     "shell.execute_reply": "2021-04-26T05:50:58.489219Z"
    },
    "papermill": {
     "duration": 1.355131,
     "end_time": "2021-04-26T05:50:58.489864",
     "exception": false,
     "start_time": "2021-04-26T05:50:57.134733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "trained-tiger",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:51:01.433549Z",
     "iopub.status.busy": "2021-04-26T05:51:01.432633Z",
     "iopub.status.idle": "2021-04-26T05:51:01.437975Z",
     "shell.execute_reply": "2021-04-26T05:51:01.438673Z"
    },
    "papermill": {
     "duration": 1.580513,
     "end_time": "2021-04-26T05:51:01.438863",
     "exception": false,
     "start_time": "2021-04-26T05:50:59.858350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 101,125\n",
      "Trainable params: 101,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "described-matthew",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:51:04.016096Z",
     "iopub.status.busy": "2021-04-26T05:51:04.015183Z",
     "iopub.status.idle": "2021-04-26T05:51:04.020376Z",
     "shell.execute_reply": "2021-04-26T05:51:04.019858Z"
    },
    "papermill": {
     "duration": 1.28832,
     "end_time": "2021-04-26T05:51:04.020487",
     "exception": false,
     "start_time": "2021-04-26T05:51:02.732167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "utility-alberta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:51:07.050808Z",
     "iopub.status.busy": "2021-04-26T05:51:07.049324Z",
     "iopub.status.idle": "2021-04-26T05:57:35.337334Z",
     "shell.execute_reply": "2021-04-26T05:57:35.337737Z"
    },
    "papermill": {
     "duration": 389.575032,
     "end_time": "2021-04-26T05:57:35.337940",
     "exception": false,
     "start_time": "2021-04-26T05:51:05.762908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 - 15s - loss: 0.9691 - accuracy: 0.5913 - val_loss: 0.8071 - val_accuracy: 0.6923\n",
      "Epoch 2/25\n",
      "375/375 - 14s - loss: 0.7936 - accuracy: 0.6748 - val_loss: 0.6961 - val_accuracy: 0.7185\n",
      "Epoch 3/25\n",
      "375/375 - 14s - loss: 0.7313 - accuracy: 0.7015 - val_loss: 0.6656 - val_accuracy: 0.7337\n",
      "Epoch 4/25\n",
      "375/375 - 15s - loss: 0.6941 - accuracy: 0.7187 - val_loss: 0.6353 - val_accuracy: 0.7482\n",
      "Epoch 5/25\n",
      "375/375 - 15s - loss: 0.6693 - accuracy: 0.7317 - val_loss: 0.6087 - val_accuracy: 0.7493\n",
      "Epoch 6/25\n",
      "375/375 - 14s - loss: 0.6530 - accuracy: 0.7361 - val_loss: 0.5939 - val_accuracy: 0.7665\n",
      "Epoch 7/25\n",
      "375/375 - 16s - loss: 0.6419 - accuracy: 0.7423 - val_loss: 0.5875 - val_accuracy: 0.7712\n",
      "Epoch 8/25\n",
      "375/375 - 14s - loss: 0.6286 - accuracy: 0.7491 - val_loss: 0.5946 - val_accuracy: 0.7533\n",
      "Epoch 9/25\n",
      "375/375 - 15s - loss: 0.6226 - accuracy: 0.7502 - val_loss: 0.5776 - val_accuracy: 0.7630\n",
      "Epoch 10/25\n",
      "375/375 - 15s - loss: 0.6153 - accuracy: 0.7529 - val_loss: 0.5784 - val_accuracy: 0.7775\n",
      "Epoch 11/25\n",
      "375/375 - 39s - loss: 0.6099 - accuracy: 0.7563 - val_loss: 0.5543 - val_accuracy: 0.7717\n",
      "Epoch 12/25\n",
      "375/375 - 16s - loss: 0.6030 - accuracy: 0.7586 - val_loss: 0.5602 - val_accuracy: 0.7798\n",
      "Epoch 13/25\n",
      "375/375 - 14s - loss: 0.5973 - accuracy: 0.7636 - val_loss: 0.5616 - val_accuracy: 0.7782\n",
      "Epoch 14/25\n",
      "375/375 - 14s - loss: 0.5940 - accuracy: 0.7634 - val_loss: 0.5448 - val_accuracy: 0.7855\n",
      "Epoch 15/25\n",
      "375/375 - 15s - loss: 0.5893 - accuracy: 0.7668 - val_loss: 0.5427 - val_accuracy: 0.7870\n",
      "Epoch 16/25\n",
      "375/375 - 14s - loss: 0.5867 - accuracy: 0.7663 - val_loss: 0.5423 - val_accuracy: 0.7952\n",
      "Epoch 17/25\n",
      "375/375 - 14s - loss: 0.5859 - accuracy: 0.7670 - val_loss: 0.5363 - val_accuracy: 0.7940\n",
      "Epoch 18/25\n",
      "375/375 - 15s - loss: 0.5780 - accuracy: 0.7712 - val_loss: 0.5339 - val_accuracy: 0.7985\n",
      "Epoch 19/25\n",
      "375/375 - 15s - loss: 0.5775 - accuracy: 0.7720 - val_loss: 0.5283 - val_accuracy: 0.7935\n",
      "Epoch 20/25\n",
      "375/375 - 14s - loss: 0.5726 - accuracy: 0.7736 - val_loss: 0.5255 - val_accuracy: 0.7937\n",
      "Epoch 21/25\n",
      "375/375 - 15s - loss: 0.5734 - accuracy: 0.7716 - val_loss: 0.5227 - val_accuracy: 0.7960\n",
      "Epoch 22/25\n",
      "375/375 - 14s - loss: 0.5695 - accuracy: 0.7749 - val_loss: 0.5186 - val_accuracy: 0.7912\n",
      "Epoch 23/25\n",
      "375/375 - 14s - loss: 0.5698 - accuracy: 0.7759 - val_loss: 0.5159 - val_accuracy: 0.8007\n",
      "Epoch 24/25\n",
      "375/375 - 15s - loss: 0.5666 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7982\n",
      "Epoch 25/25\n",
      "375/375 - 14s - loss: 0.5651 - accuracy: 0.7780 - val_loss: 0.5196 - val_accuracy: 0.7983\n",
      "--- 388.28542041778564 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history3 = model3.fit(datagen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs, \n",
    "                              validation_data = (x_val, y_val), verbose=2, \n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                              callbacks = [reduce_lr])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "seasonal-collector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T05:57:38.189896Z",
     "iopub.status.busy": "2021-04-26T05:57:38.188958Z",
     "iopub.status.idle": "2021-04-26T05:57:38.568037Z",
     "shell.execute_reply": "2021-04-26T05:57:38.568453Z"
    },
    "papermill": {
     "duration": 1.714059,
     "end_time": "2021-04-26T05:57:38.568611",
     "exception": false,
     "start_time": "2021-04-26T05:57:36.854552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7983\n",
      "Loss: 0.5196\n",
      "Accuracy: 0.7983\n",
      "--- 0.3760824203491211 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "score = model3.evaluate(x_val, y_val)\n",
    "\n",
    "print('Loss: {:.4f}'.format(score[0]))\n",
    "print('Accuracy: {:.4f}'.format(score[1]))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-honduras",
   "metadata": {
    "papermill": {
     "duration": 1.776878,
     "end_time": "2021-04-26T05:57:41.615465",
     "exception": false,
     "start_time": "2021-04-26T05:57:39.838587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Note :**\n",
    "- Each model evaluation, performance and comparision performed in CM6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2297.950887,
   "end_time": "2021-04-26T05:57:46.197251",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-26T05:19:28.246364",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
